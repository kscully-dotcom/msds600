{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a68f23f5",
   "metadata": {},
   "source": [
    "# Week 8: Social media sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4e0e66",
   "metadata": {},
   "source": [
    "This final week we are analyzing our social media data with sentiment analysis. There are a few ways to perform sentiment analysis:\n",
    "\n",
    "- use a dictionary lookup: words have corresponding sentiment values we use to calculate overall sentiment for a text chunk\n",
    "    - scores can range from -1 to +1 or another range\n",
    "    - we can add other rules for negations (e.g. the word 'not' flips the sign of the score for the next word)\n",
    "- use a machine learning model; train a classifier on labeled data\n",
    "    - label can be -1, 0, or +1 for negative, neutral, or positive\n",
    "    \n",
    "We will start with a demonstration of the keyword lookup method and also cover the machine learning method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c195379",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62c0cc6",
   "metadata": {},
   "source": [
    "First we need to load our data from our SQLite database we saved last week:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80beb7e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "      <th>author</th>\n",
       "      <th>n_comments</th>\n",
       "      <th>score</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Red Rocks, 1974 John Denver concert</td>\n",
       "      <td>/r/Colorado/comments/mug406/red_rocks_1974_joh...</td>\n",
       "      <td>Mellotime</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td></td>\n",
       "      <td>mug406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Hiking the Royal Gorge in a spring snowstorm</td>\n",
       "      <td>/r/Colorado/comments/muffdl/hiking_the_royal_g...</td>\n",
       "      <td>TaipeiPersonality_</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td></td>\n",
       "      <td>muffdl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Rocky Mountain National Park this weekend!</td>\n",
       "      <td>/r/Colorado/comments/mufe4j/rocky_mountain_nat...</td>\n",
       "      <td>TaipeiPersonality_</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td></td>\n",
       "      <td>mufe4j</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Milky way at Loveland Pass last weekend</td>\n",
       "      <td>/r/Colorado/comments/mud617/milky_way_at_lovel...</td>\n",
       "      <td>Sutitan</td>\n",
       "      <td>35</td>\n",
       "      <td>692</td>\n",
       "      <td></td>\n",
       "      <td>mud617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Weminuche Wilderness</td>\n",
       "      <td>/r/Colorado/comments/mu835a/weminuche_wilderness/</td>\n",
       "      <td>finerminer17</td>\n",
       "      <td>13</td>\n",
       "      <td>189</td>\n",
       "      <td></td>\n",
       "      <td>mu835a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>912</td>\n",
       "      <td>Hoarfrost on one of my sundials this brisk mor...</td>\n",
       "      <td>/r/Colorado/comments/kcnpj5/hoarfrost_on_one_o...</td>\n",
       "      <td>IronRainForge</td>\n",
       "      <td>5</td>\n",
       "      <td>78</td>\n",
       "      <td></td>\n",
       "      <td>kcnpj5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>913</td>\n",
       "      <td>The Stanley Hotel after some snow</td>\n",
       "      <td>/r/Colorado/comments/kclire/the_stanley_hotel_...</td>\n",
       "      <td>TFG4</td>\n",
       "      <td>9</td>\n",
       "      <td>251</td>\n",
       "      <td></td>\n",
       "      <td>kclire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>914</td>\n",
       "      <td>The stanley hotel in Estes in October</td>\n",
       "      <td>/r/Colorado/comments/kclfwi/the_stanley_hotel_...</td>\n",
       "      <td>TFG4</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td></td>\n",
       "      <td>kclfwi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>915</td>\n",
       "      <td>Picture my dad took - Sawatch Range just SW of...</td>\n",
       "      <td>/r/Colorado/comments/kckwut/picture_my_dad_too...</td>\n",
       "      <td>theredcameron</td>\n",
       "      <td>6</td>\n",
       "      <td>95</td>\n",
       "      <td></td>\n",
       "      <td>kckwut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>916</td>\n",
       "      <td>Favorite spot of the summer. Dolores SWA, publ...</td>\n",
       "      <td>/r/Colorado/comments/kcjf3v/favorite_spot_of_t...</td>\n",
       "      <td>snowsurfer2110</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td></td>\n",
       "      <td>kcjf3v</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>917 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                              title  \\\n",
       "0        0                Red Rocks, 1974 John Denver concert   \n",
       "1        1       Hiking the Royal Gorge in a spring snowstorm   \n",
       "2        2         Rocky Mountain National Park this weekend!   \n",
       "3        3            Milky way at Loveland Pass last weekend   \n",
       "4        4                               Weminuche Wilderness   \n",
       "..     ...                                                ...   \n",
       "912    912  Hoarfrost on one of my sundials this brisk mor...   \n",
       "913    913                  The Stanley Hotel after some snow   \n",
       "914    914              The stanley hotel in Estes in October   \n",
       "915    915  Picture my dad took - Sawatch Range just SW of...   \n",
       "916    916  Favorite spot of the summer. Dolores SWA, publ...   \n",
       "\n",
       "                                                  link              author  \\\n",
       "0    /r/Colorado/comments/mug406/red_rocks_1974_joh...           Mellotime   \n",
       "1    /r/Colorado/comments/muffdl/hiking_the_royal_g...  TaipeiPersonality_   \n",
       "2    /r/Colorado/comments/mufe4j/rocky_mountain_nat...  TaipeiPersonality_   \n",
       "3    /r/Colorado/comments/mud617/milky_way_at_lovel...             Sutitan   \n",
       "4    /r/Colorado/comments/mu835a/weminuche_wilderness/        finerminer17   \n",
       "..                                                 ...                 ...   \n",
       "912  /r/Colorado/comments/kcnpj5/hoarfrost_on_one_o...       IronRainForge   \n",
       "913  /r/Colorado/comments/kclire/the_stanley_hotel_...                TFG4   \n",
       "914  /r/Colorado/comments/kclfwi/the_stanley_hotel_...                TFG4   \n",
       "915  /r/Colorado/comments/kckwut/picture_my_dad_too...       theredcameron   \n",
       "916  /r/Colorado/comments/kcjf3v/favorite_spot_of_t...      snowsurfer2110   \n",
       "\n",
       "     n_comments  score text      id  \n",
       "0             1     28       mug406  \n",
       "1             1     19       muffdl  \n",
       "2             2     19       mufe4j  \n",
       "3            35    692       mud617  \n",
       "4            13    189       mu835a  \n",
       "..          ...    ...  ...     ...  \n",
       "912           5     78       kcnpj5  \n",
       "913           9    251       kclire  \n",
       "914           1     44       kclfwi  \n",
       "915           6     95       kckwut  \n",
       "916           4     34       kcjf3v  \n",
       "\n",
       "[917 rows x 8 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "con = sqlite3.connect('co_reddit.sqlite')\n",
    "df = pd.read_sql_query('SELECT * from posts;', con)\n",
    "con.close()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbf56f9",
   "metadata": {},
   "source": [
    "Since most of our text is missing for this subreddit, we'll just use the title of the posts. However, if you have text from each post or comments for each post, you could combine those with the title."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb82b81c",
   "metadata": {},
   "source": [
    "# Keyword sentiment "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af814733",
   "metadata": {},
   "source": [
    "We will start with a keyword sentiment analysis technique. Let's first load a dictionary of words and sentiment values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9977131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_df = pd.read_csv('AFINN-en-165.txt', sep='\\t', names=['word', 'score'], index_col='word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "328aa462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>abandon</th>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandoned</th>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandons</th>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abducted</th>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abduction</th>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yucky</th>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yummy</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zealot</th>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zealots</th>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zealous</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3382 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           score\n",
       "word            \n",
       "abandon       -2\n",
       "abandoned     -2\n",
       "abandons      -2\n",
       "abducted      -2\n",
       "abduction     -2\n",
       "...          ...\n",
       "yucky         -2\n",
       "yummy          3\n",
       "zealot        -2\n",
       "zealots       -2\n",
       "zealous        2\n",
       "\n",
       "[3382 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41e254d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_dict = sentiment_df.to_dict()['score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cb515c",
   "metadata": {},
   "source": [
    "Here, we load the data into a dataframe. There is no header so we provide the column names with the `names` argument. Then we set the word as the index, which helps with the next step where we convert the dataframe to a dictionary. This has the column names as keys, then the values are dictionaries with the index value as keys and the column values as values. So we get a dictionary like this:\n",
    "\n",
    "```python\n",
    "{'abandon': -2,\n",
    " 'abandoned': -2,\n",
    " 'abandons': -2,\n",
    " 'abducted': -2,\n",
    " ...\n",
    "}\n",
    "```\n",
    "\n",
    "Now we can get the average sentiment for each string we have in our original dataframe, which is the title of each post. We get the scores for each word and take the average for each title:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99da374f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "title_sentiments = []\n",
    "for title in df['title']:\n",
    "    words = title.lower().split()\n",
    "    this_titles_sentiments = []\n",
    "    for w in words:\n",
    "        if w in sentiment_dict.keys():\n",
    "            this_titles_sentiments.append(sentiment_dict[w])\n",
    "        else:\n",
    "            this_titles_sentiments.append(0)\n",
    "            \n",
    "    \n",
    "    title_sentiments.append(np.mean(this_titles_sentiments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "816aac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['keyword_sentiment'] = title_sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebb4d600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['keyword_sentiment'].plot.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ac7344a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0412800450004885"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['keyword_sentiment'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9a57a8",
   "metadata": {},
   "source": [
    "We can easily create a new column in our original dataframe with sentiments and then use it to create plots. Since this lookup dictionary method doesn't have a lot of words,  we get a lot of 0 scores. These don't necessarily mean the sentiments are neutral, but may mean that no words were in the lookup dictionary. Overall, we can see the sentiments trend towards a positive value.\n",
    "\n",
    "A more interesting result might be had by looking at the sentiment for comments on posts. Last week in the advanced section we collected comments on posts. We can perform a similar analysis as above on the comments to see what the sentiment is on each post. Then we can combine the posts and comments dataframes to see the titles of the posts with some of the most positive and negative sentiments to help us understand what some of the most positive and negative topics are in the subreddit. This is left as an optional challenge for you in the assignment.\n",
    "\n",
    "Let's look at some of the top and bottom sentiment posts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b5df26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>keyword_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Colorado judge strikes down Boulder’s assault ...</td>\n",
       "      <td>-0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>Arrests made in deadly Green Valley Ranch arson</td>\n",
       "      <td>-0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>7 Injured, 1 Killed In Berthoud Pass Head-On C...</td>\n",
       "      <td>-0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>9News, Parent Company Accused of Racist Behavi...</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Animal cruelty initiative irks Colorado ranchers</td>\n",
       "      <td>-0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>Good morning Colorado!</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>Colorados beautiful nature</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>Great White Buffalo</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>738</th>\n",
       "      <td>Love the beautiful snowy Rockies!</td>\n",
       "      <td>1.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>Beautiful Ouray</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>917 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  keyword_sentiment\n",
       "181  Colorado judge strikes down Boulder’s assault ...          -0.625000\n",
       "508    Arrests made in deadly Green Valley Ranch arson          -0.625000\n",
       "635  7 Injured, 1 Killed In Berthoud Pass Head-On C...          -0.555556\n",
       "52   9News, Parent Company Accused of Racist Behavi...          -0.500000\n",
       "105   Animal cruelty initiative irks Colorado ranchers          -0.500000\n",
       "..                                                 ...                ...\n",
       "780                             Good morning Colorado!           1.000000\n",
       "860                         Colorados beautiful nature           1.000000\n",
       "380                                Great White Buffalo           1.000000\n",
       "738                  Love the beautiful snowy Rockies!           1.200000\n",
       "524                                    Beautiful Ouray           1.500000\n",
       "\n",
       "[917 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='keyword_sentiment')[['title', 'keyword_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c73774d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Colorado judge strikes down Boulder’s assault weapons ban',\n",
       " 'Arrests made in deadly Green Valley Ranch arson',\n",
       " '7 Injured, 1 Killed In Berthoud Pass Head-On Crash',\n",
       " '9News, Parent Company Accused of Racist Behavior in Federal Filing',\n",
       " 'Animal cruelty initiative irks Colorado ranchers',\n",
       " 'Muslim groups mourn and raise money for Colorado shooting victims',\n",
       " 'MISSING PERSON— Marlena Mizell',\n",
       " 'Dismal snow at Loveland',\n",
       " 'Three backcountry skiers killed in Colorado avalanche',\n",
       " 'Parker mayor denies knowledge of QAnon and conspiracy theories that he tweeted.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full titles of the bottom 10 sentiments\n",
    "df.sort_values(by='keyword_sentiment')['title'].to_list()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2be5eb5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Beautiful Ouray',\n",
       " 'Love the beautiful snowy Rockies!',\n",
       " 'Mt. Champion',\n",
       " 'Colorados beautiful nature',\n",
       " 'Great White Buffalo',\n",
       " 'Glorious morning',\n",
       " 'Hello Beautiful 💕',\n",
       " 'Good morning Colorado!',\n",
       " 'Super rad, this guy wins Colorado today. 🤘🏼',\n",
       " 'The beautiful Great Sand Dunes National Park']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full titles of the top 10 sentiments\n",
    "df.sort_values(by='keyword_sentiment', ascending=False)['title'].to_list()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27ad43b",
   "metadata": {},
   "source": [
    "# Using Python packages for sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed81e60",
   "metadata": {},
   "source": [
    "There are a few Python packages that use rule-based and keyword-based sentiment analysis. We will look at VADER and textblob here, although there are probably more. We need to install these first: `conda install -c conda-forge textblob vadersentiment -y`. Another option we won't cover here is the `flair` package. We can use textblob and vader like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b5c0b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.85, subjectivity=1.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "tb = TextBlob(\"April snowstorms make for some beautiful pictures...\")\n",
    "tb.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc85e55a",
   "metadata": {},
   "source": [
    "Textblob requires us to use their TextBlob class on a string. Then we can get the sentiment score. It gives us polarity (-1 to =1) and subjectivite (0 to 1, objective to subjective). We can see this sentence is rated fully subjective and has a positive sentiment, which makes sense. We can apply it to the whole dataframe like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b77bab30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tb_sentiment(text):\n",
    "    tb = TextBlob(text)\n",
    "    return tb.sentiment[0]\n",
    "\n",
    "df['tb_sentiment'] = df['title'].apply(get_tb_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269340c2",
   "metadata": {},
   "source": [
    "Because we need to do a few steps to get the polarity (sentiment) score, we wrote a short function to do it. Then we use the pandas `apply` function to apply this to the whole dataframe.\n",
    "\n",
    "Note: If you have a lot of data and want to speed this up, look at the `swifter` package for parallelizing the `apply` function.\n",
    "\n",
    "Now we can look at the distribution of these sentiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5f6928d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['tb_sentiment'].plot.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbcbd5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09054171818604066"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tb_sentiment'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b534b199",
   "metadata": {},
   "source": [
    "We can see the distribution looks similar but is more spread out than our AFINN method. textblob has more words in its lookup dictionary than the AFINN dictionary we used.\n",
    "\n",
    "VADER is similar to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52d55aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.606, 'pos': 0.394, 'compound': 0.5994}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "analyzer.polarity_scores(\"April snowstorms make for some beautiful pictures...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04e7f39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5994"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer.polarity_scores(\"April snowstorms make for some beautiful pictures...\")['compound']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0409060",
   "metadata": {},
   "source": [
    "Vader provides a breakdown of the negative, positive, an neutral scores, as well as an overall score called 'compound'. We can simply use the 'compound' score as our overall sentiment score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad38d88e",
   "metadata": {},
   "source": [
    "# Optional advanced section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9597005f",
   "metadata": {},
   "source": [
    "## Word vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5840cbd9",
   "metadata": {},
   "source": [
    "Word vectors allow us to do more advanced NLP, like topic modeling, ML, and more. These might also be called text embeddings or word embeddings. We can train our own models to create these, or use pre-built vectors like GLoVe and Word2Vec. You can read more about the different ways how word embeddings/vectors are created [here](https://machinelearningmastery.com/what-are-word-embeddings/).\n",
    "\n",
    "One of the easier ways to extract word embeddings is with the SpaCy NLP Python package. An example is [here](https://spacy.io/usage/embeddings-transformers) in the documentation (there is also a nice free course on SpaCy by one of the creators [here](https://course.spacy.io/en/))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f772a7b0",
   "metadata": {},
   "source": [
    "## Using machine learning for sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5235505e",
   "metadata": {},
   "source": [
    "If you are being very advanced, you might use word embeddings to train a ML model or topic model on the data. However, you can also do it with simpler features, like word counts (or a version of normalized word counts called TFIDF). The NLTK documentation shows an example of how to train a ML model for sentiment analysis [here](http://www.nltk.org/howto/sentiment.html). Like all ML models, the quality of predictions depends on the training data. So ideally, we would want similar training data to what we will use our model on. Many examples will use movie reviews as their training data, and so may not work well on social media data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612b080e",
   "metadata": {},
   "source": [
    "## Topic modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb464d3",
   "metadata": {},
   "source": [
    "One fun way to analyze text is with topic modeling. This groups text into topics, and we can extract the top words out of these topics. In this way, we can see the general themes of what people are talking about. One package for doing this in Python is Gensim, and there are a few tutorials out there, such as [this one](https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/), showing how to perform topic modeling with Gensim. In our case, it would be interesting to look at the main topics of a subreddit to see what people are talking about."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
